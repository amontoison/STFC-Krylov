{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Krylov.jl: A Julia basket of hand-picked Krylov methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_STFC-Rutherford Appleton Laboratory, England_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Thursday December 8, 2022_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Alexis Montoison_** (alexis.montoison@polymtl.ca), **_Dominique Orban_** (dominique.orban@polymtl.ca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How a Julia code can be both generic and efficient?\n",
    "### How to support variable precision and architectures?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using Pkg, LinearAlgebra, SparseArrays\n",
    "pkg\"activate .\"   # Activate the environment with the file Project.toml at `.`\n",
    "pkg\"instantiate\"  # Download all the packages declared in the Manifest.toml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkg\"status\"  # Print out the status of the project/manifest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_packages = false\n",
    "if additional_packages\n",
    "  Pkg.add(\"BFloat16s\")    # https://github.com/JuliaMath/BFloat16s.jl\n",
    "  Pkg.add(\"MultiFloats\")  # https://github.com/dzhang314/MultiFloats.jl   \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = false\n",
    "if gpu\n",
    "  Pkg.add(\"CUDA\")    # Nvidia GPUs\n",
    "  Pkg.add(\"AMDGPU\")  # AMD GPUs\n",
    "  Pkg.add(\"OneAPI\")  # Intel GPUs\n",
    "  Pkg.add(\"Metal\")   # Apple M1 GPUs\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkg\"up\" # Update all packages of the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I) Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Krylov.jl](https://github.com/JuliaSmoothOptimizers/Krylov.jl) is a Julia package that implements a collection of Krylov processes and methods for solving a variety of linear problems:\n",
    "\n",
    "|  Square systems | Linear least-squares problems |Linear least-norm problems              |\n",
    "|:---------------:|:-----------------------------:|:--------------------------------------:|\n",
    "| $Ax = b$        | $\\min \\|b - Ax\\|$             |$\\min \\|x\\|  \\text{  s.t.  }  Ax = b$ |\n",
    "\n",
    "| Adjoint systems | Saddle-point and Hermitian quasi-definite systems | Generalized saddle-point and non-Hermitian partitioned systems |\n",
    "|:---------------:|:-------------------------------------------------:|:--------------------------------------------------------------:|\n",
    "|$\\begin{matrix} Ax = b \\\\ A^{H} y = c \\end{matrix}$ | $\\begin{bmatrix} M & A \\\\ A^{H} & -N \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} = \\begin{bmatrix} b \\\\ c \\end{bmatrix}$ | $\\begin{bmatrix} M & A \\\\ B & N \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} = \\begin{bmatrix} b \\\\ c \\end{bmatrix}$ |\n",
    "\n",
    "$A^{H\\!}$ denotes the conjugate transpose of $A$.\n",
    "It coincides with $A^{T\\!}$, the transpose of $A$, if $A$ is real.\n",
    "Krylov methods are iterative methods based on Krylov subspaces.\n",
    "\n",
    "They are an alternative to direct methods such as Gaussian elimination or QR decomposition when storage requirements or computational costs become prohibitive, which is often the case for large and sparse linear problems.\n",
    "\n",
    "Contrary to direct methods, which require storing $A$ explicitly, Krylov methods support linear operators to model operator-vector products $u \\leftarrow Av$, and in some instances $u \\leftarrow A^{H\\!}w$ because Krylov processes only require those operations to build Krylov subspaces.\n",
    "\n",
    "The same goes with preconditioners, i.e., transformations that modify a linear system into an \n",
    "equivalent form with favorable spectral properties that may yield faster convergence in finite-precision arithmetic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Cayley-Hamilton theorem__:\n",
    "If $A$ is a square matrix of size $n$ and $p(X) = \\det(XI_n - A) = X^n + p_{n-1} X^{n-1} + \\dots + p_1 X + p_0$ is its characteristic polynomial, then $p(A) = A^n + p_{n-1} A^{n-1} + \\dots + p_1 A + p_0 I_n = 0_n$.\n",
    "<br/><br/>\n",
    "If $A$ is nonsingular, $p_0 \\ne 0$ and\n",
    "$$A^{-1} = -\\dfrac{1}{p_0}(A^{n-1} + p_{n-1} A^{n-2} + \\dots + p_1 I_n)$$\n",
    "<br/><br/>\n",
    "$$x = A^{-1}b \\implies x\\in K_n(A, b) = \\mathop{\\mathrm{Span}} \\{b, Ab, \\dots, A^{n-1}b\\}$$\n",
    "<br/><br/>\n",
    "$K_n(A, b)$ is a *Krylov subspace*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Principle of Krylov methods__: Build iteratively a solution $x_k \\in K_k(A,b)$ of $Ax=b$.\n",
    "<br/><br/>\n",
    "A process is used to build an (orthogonal) basis of $K_k(A, b)$.\n",
    "We have the Lanczos process for Hermitian matrices and the Arnoldi process for square non-Hermitian matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The projection of $A$ into the Krylov subspace has a workable structure and $x_k = V_k y_k$, where $y_k \\in \\mathbb{R}^k$ is the solution of a subproblem that uses the projection of $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When $A$ is rectangular, we use the Golub-Kahan process to build orthogonal bases of $K_k(A^T A, A^T b)$ and $K_k(A A^T, b)$ and we use the normal equations to solve linear least-squares and least-norm problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We refer interested readers to [ipsen-meyer-1998](https://doi.org/10.1080/00029890.1998.12004985) for an introduction to Krylov methods along with [greenbaum-1997](https://doi.org/10.1137/1.9781611970937) and [saad-2003](https://doi.org/10.1137/1.9780898718003) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SuiteSparse Matrix Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [SuiteSparse Matrix Collection](https://sparse.tamu.edu/) (previously UFL collection) gathers about 3000 problems from multiple fields and of multiple sizes. The collection is often used in scientific papers. It allows easy testing and comparison of new implementations of direct and iterative methods.\n",
    "<br/><br/>\n",
    "Each problem is stored in the format *MatrixMarket* (.mtx), *MAT* (.mat) and *Rutherford-Boeing* (.rb).\n",
    "An interface to the SuiteSparse Matrix Collection exists in Julia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using SuiteSparseMatrixCollection\n",
    "using HarwellRutherfordBoeing\n",
    "using MatrixMarket\n",
    "using MAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database\n",
    "ssmc = ssmc_db(verbose=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spd = ssmc[(ssmc.numerical_symmetry .== 1) .& (ssmc.positive_definite.== true) .& (ssmc.real .== true).& (ssmc.nrows .≤ 100), :]\n",
    "paths = fetch_ssmc(spd, format=\"MM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = paths[1]\n",
    "A = MatrixMarket.mmread(joinpath(path, \"$(spd.name[1]).mtx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_matrix(name :: String)\n",
    "    # Get information about the matrix\n",
    "    pb = ssmc_matrices(ssmc, \"\", name)\n",
    "    \n",
    "    # Download the matrix\n",
    "    paths = fetch_ssmc(pb, format=\"MM\")\n",
    "    path_mtx = paths[1]\n",
    "\n",
    "    # Load the matrix\n",
    "    mtx = MatrixMarket.mmread(joinpath(path_mtx, \"$name.mtx\"))\n",
    "    return mtx\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = get_matrix(\"sherman5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  II) Largest collection of Krylov processes and methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krylov.jl aims to provide a unified interface for the largest collection of Krylov processes and methods, all programming languages taken together, with six and thirty-three implementations, respectively:\n",
    "\n",
    "- **Krylov processes**: [_Arnoldi_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/processes/#Arnoldi), [_Golub-Kahan_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/processes/#Golub-Kahan), [_Hermitian Lanczos_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/processes/#Hermitian-Lanczos), [_Montoison-Orban_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/processes/#Montoison-Orban), [_Non-Hermitian Lanczos_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/processes/#Non-Hermitian-Lanczos), [_Saunders-Simon-Yip_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/processes/#Saunders-Simon-Yip);\n",
    "- **Krylov methods**: [_Bicgstab_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/solvers/unsymmetric/#BiCGSTAB), [_Bilq_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/solvers/unsymmetric/#BiLQ), [_Bilqr_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/solvers/as/#BiLQR), [_Cg_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/solvers/spd/#CG), [_Cg-lanczos_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/solvers/spd/#CG-LANCZOS), [_Cg-lanczos-shift_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/solvers/spd/#CG-LANCZOS-SHIFT), [_Cgls_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/solvers/ls/#CGLS), [_Cgne_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/solvers/ln/#CGNE), [_Cgs_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/solvers/unsymmetric/#CGS), [_Cr_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/solvers/spd/#CR), [_Craig_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/solvers/ln/#CRAIG), [_Craigmr_](), [_Crls_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/solvers/ls/#CRLS), [_Crmr_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/solvers/ln/#CRMR), [_Diom_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/solvers/unsymmetric/#DIOM), [_Dqgmres_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/solvers/unsymmetric/#DQGMRES), [_Fgmres_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/solvers/unsymmetric/#FGMRES), [_Fom_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/solvers/unsymmetric/#FOM), [_Gmres_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/solvers/unsymmetric/#GMRES), [_Gpmr_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/solvers/gsp/#GPMR), [_Lnlq_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/solvers/ln/#LNLQ), [_Lslq_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/solvers/ls/#LSLQ), [_Lsmr_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/solvers/ls/#LSMR), [_Lsqr_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/solvers/ls/#LSQR), [_Minres_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/solvers/sid/#MINRES), [_Minres-qlp_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/solvers/sid/#MINRES-QLP), [_Qmr_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/solvers/unsymmetric/#QMR), [_Symmlq_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/solvers/sid/#SYMMLQ), [_Tricg_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/solvers/sp_sqd/#TriCG), [_Trilqr_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/solvers/as/#TriLQR), [_Trimr_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/solvers/sp_sqd/#TriMR), [_Usymlq_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/solvers/ln/#CRAIGMR), [_Usymqr_](https://juliasmoothoptimizers.github.io/Krylov.jl/dev/solvers/ls/#USYMQR).\n",
    "\n",
    "Some processes and methods are not available elsewhere and are the product of our own research. References for each process and method are available in the extensive [documentation](https://juliasmoothoptimizers.github.io/Krylov.jl/stable/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Krylov\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hermitian positive definite linear systems (**cg**, **cr**, **cg_lanczos**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = get_matrix(\"1138_bus\")\n",
    "n, m = size(A)\n",
    "b = ones(n)\n",
    "x, stats = cg(A, b, history=true)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(0:stats.niter, stats.residuals, label=\"CG\", xlabel=\"k\", ylabel=\"‖rₖ‖\", yaxis=:log10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm(b - A*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hermitian indefinite linear systems (**symmlq**, **minres**, **minres_qlp**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = get_matrix(\"meg4\")\n",
    "n, m = size(A)\n",
    "b = ones(n)\n",
    "x, stats = cg(A, b, history=true)  # symmlq, minres\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(0:stats.niter, stats.residuals, label=\"CG\", xlabel=\"k\", ylabel=\"‖rₖ‖\", yaxis=:log10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm(b - A*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Square non-Hermitian linear systems (**bilq**, **qmr**, **usymlq**, **usymqr**, **cgs**, **bicgstab**, **diom**, **fom**, **dqgmres**, **gmres**, **fgmres**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = get_matrix(\"orani678\")\n",
    "n, m = size(A)\n",
    "b = ones(n)\n",
    "x, stats = gmres(A, b, history=true)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(0:stats.niter, stats.residuals, label=\"GMRES\", xlabel=\"k\", ylabel=\"‖rₖ‖\", yaxis=:log10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm(b - A*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Least-norm problems (**cgne**, **crmr**, **lnlq**, **craig**, **craigmr**, **usymlq**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = get_matrix(\"well1033\")'\n",
    "n, m = size(A)\n",
    "b = rand(n)\n",
    "x, y, stats = craigmr(A, b, history=true)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm(b - A*A'*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm(b - A*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Least-squares problems (**cgls**, **crls**, **lslq**, **lsqr**, **lsmr**, **usymqr**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = get_matrix(\"well1850\")\n",
    "n, m = size(A)\n",
    "b = rand(n)\n",
    "x, stats = lsqr(A, b, history=true)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm(A'*b - A'A*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adjoint systems (**bilqr**, **trilqr**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = get_matrix(\"arc130\")\n",
    "n, m = size(A)\n",
    "b = rand(n)\n",
    "c = rand(m)\n",
    "x, y, stats = bilqr(A, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm(b - A*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm(c - A'*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = get_matrix(\"illc1033\")\n",
    "m, n = size(A)\n",
    "b = ones(m)\n",
    "c = -ones(n)\n",
    "\n",
    "K = [I A; A' -I]\n",
    "d = [b; c]\n",
    "\n",
    "(x, y, stats) = tricg(A, b, c)\n",
    "r =  d - K * [x; y]\n",
    "norm(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = diagm(0 => [3.0 * i for i = 1:m])\n",
    "N = diagm(0 => [5.0 * i for i = 1:n])\n",
    "M⁻¹ = inv(M)\n",
    "N⁻¹ = inv(N)\n",
    "\n",
    "K = [M A; A' -N]\n",
    "(x, y, stats) = tricg(A, b, c, M=M⁻¹, N=N⁻¹)\n",
    "r =  d - K * [x; y]\n",
    "norm(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generalized saddle-point and non-Hermitian partitioned systems (**gpmr**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [1.0 0.0; 0.0 -1.0; 3.0 0.0]\n",
    "B = [0.0 2.0 4.0; -3.0 0.0 0.0]\n",
    "n, m = size(A)\n",
    "b = ones(n)\n",
    "c = -ones(m)\n",
    "\n",
    "K = [I A; B I]\n",
    "d = [b; c]\n",
    "\n",
    "x, y, stats = gpmr(A, B, b, c)\n",
    "r =  d - K * [x; y]\n",
    "norm(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = diagm(0 => [2.0 * i for i = 1:n])\n",
    "N = diagm(0 => [16.0 * i for i = 1:m])\n",
    "M⁻¹ = inv(M)\n",
    "N⁻¹ = inv(N)\n",
    "\n",
    "K = [M A; B N]\n",
    "x, y, stats = gpmr(A, B, b, c, C=M⁻¹, D=N⁻¹)\n",
    "r =  d - K * [x; y]\n",
    "norm(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III) Support for any floating-point system supported by Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krylov.jl works with real and complex data in any floating-point system supported by Julia, which means that Krylov.jl handles any precision `T` and `Complex{T}` where `T <: AbstractFloat`.\n",
    "\n",
    "Although most personal computers offer IEEE 754 single and double precision computations, new architectures implement native computations in other floating-point systems.\n",
    "\n",
    "In addition, software libraries such as the GNU MPFR, shipped with Julia, let users experiment with computations in variable, extended precision at the software level with the `BigFloat` data type.\n",
    "\n",
    "Working in high precision has obvious benefits in terms of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Quadmath, DoubleFloats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = get_matrix(\"685_bus\")\n",
    "n, m = size(A)\n",
    "b = rand(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = Float32\n",
    "A2 = precision.(A)\n",
    "b2 = precision.(b)\n",
    "x, stats = cg(A2, b2, history=true, atol=zero(precision), rtol=zero(precision), itmax=1000)\n",
    "p = plot(0:stats.niter, stats.residuals, label=string(precision), xlabel=\"k\", ylabel=\"‖rₖ‖\", yaxis=:log10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = Float64\n",
    "A2 = precision.(A)\n",
    "b2 = precision.(b)\n",
    "x, stats = cg(A2, b2, history=true, atol=zero(precision), rtol=zero(precision), itmax=1000)\n",
    "p = plot(0:stats.niter, stats.residuals, label=string(precision), xlabel=\"k\", ylabel=\"‖rₖ‖\", yaxis=:log10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = Double64\n",
    "A2 = precision.(A)\n",
    "b2 = precision.(b)\n",
    "x, stats = cg(A2, b2, history=true, atol=zero(precision), rtol=zero(precision), itmax=1000)\n",
    "p = plot(0:stats.niter, stats.residuals, label=string(precision), xlabel=\"k\", ylabel=\"‖rₖ‖\", yaxis=:log10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = Float128\n",
    "A2 = precision.(A)\n",
    "b2 = precision.(b)\n",
    "x, stats = cg(A2, b2, history=true, atol=zero(precision), rtol=zero(precision), itmax=1000)\n",
    "plot(0:stats.niter, stats.residuals, label=string(precision), xlabel=\"k\", ylabel=\"‖rₖ‖\", yaxis=:log10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = BigFloat\n",
    "A2 = precision.(A)\n",
    "b2 = precision.(b)\n",
    "x, stats = cg(A2, b2, history=true, atol=zero(precision), rtol=zero(precision), itmax=1000)\n",
    "plot(0:stats.niter, stats.residuals, label=string(precision), xlabel=\"k\", ylabel=\"‖rₖ‖\", yaxis=:log10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV) Support for Nvidia, AMD and Intel GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krylov methods are well suited for GPU computations because they only require operator-vector products ($u \\leftarrow Av$, $u \\leftarrow A^{H\\!}w$) and vector operations ($\\|v\\|$, $u^H v$, $v \\leftarrow \\alpha u + \\beta v$), which are highly parallelizable.\n",
    "\n",
    "The implementations in Krylov.jl are generic so as to take advantage of the multiple dispatch and broadcast features of Julia.\n",
    "\n",
    "Those allow the implementations to be specialized automatically by the compiler for both CPU and GPU.\n",
    "\n",
    "Thus, Krylov.jl works with GPU backends that build on [GPUArrays.jl](https://github.com/JuliaGPU/GPUArrays.jl), such as [CUDA.jl](https://github.com/JuliaGPU/CUDA.jl), [AMDGPU.jl](https://github.com/JuliaGPU/AMDGPU.jl), [oneAPI.jl](https://github.com/JuliaGPU/oneAPI.jl) or [Metal.jl](https://github.com/JuliaGPU/Metal.jl)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![layers](https://user-images.githubusercontent.com/35051714/114203656-5b082700-9926-11eb-9332-1282c3f32348.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```julia\n",
    "V=Vector    # CPU vector\n",
    "V=CuVector  # GPU CUDA vector\n",
    "V=ROCVector # GPU ROCm vector\n",
    "V=oneArray  # GPU oneAPI vector\n",
    "\n",
    "function incrmul(a::AbstractArray,\n",
    "                 b::AbstractArray)\n",
    "                 c::AbstractArray)\n",
    "  c .+= a .* b\n",
    "end\n",
    "incrmul(a, b, c)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All solvers in Krylov.jl can be used with [CUDA.jl](https://github.com/JuliaGPU/CUDA.jl) and allow computations on Nvidia GPUs.\n",
    "Problems stored in CPU format (`Matrix` and `Vector`) must first be converted to the related GPU format (`CuMatrix` and `CuVector`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CUDA, Krylov\n",
    "\n",
    "# CPU Arrays\n",
    "A_cpu = rand(20, 20)\n",
    "b_cpu = rand(20)\n",
    "\n",
    "# GPU Arrays\n",
    "A_gpu = CuMatrix(A_cpu)\n",
    "b_gpu = CuVector(b_cpu)\n",
    "\n",
    "# Solve a square and dense system on an Nivida GPU\n",
    "x, stats = bilq(A_gpu, b_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse matrices have a specific storage on Nvidia GPUs (`CuSparseMatrixCSC`, `CuSparseMatrixCSR` or `CuSparseMatrixCOO`):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CUDA, Krylov\n",
    "using CUDA.CUSPARSE, SparseArrays\n",
    "\n",
    "# CPU Arrays\n",
    "A_cpu = sprand(200, 100, 0.3)\n",
    "b_cpu = rand(200)\n",
    "\n",
    "# GPU Arrays\n",
    "A_gpu = CuSparseMatrixCSC(A_cpu)\n",
    "b_gpu = CuVector(b_cpu)\n",
    "\n",
    "# Solve a rectangular and sparse system on an Nvidia GPU\n",
    "x, stats = lsmr(A_gpu, b_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse matrices have a specific storage on Nvidia GPUs (`CuSparseMatrixCSC`, `CuSparseMatrixCSR` or `CuSparseMatrixCOO`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Krylov, AMDGPU\n",
    "\n",
    "# CPU Arrays\n",
    "A_cpu = rand(ComplexF64, 20, 20)\n",
    "A_cpu = A_cpu + A_cpu'\n",
    "b_cpu = rand(ComplexF64, 20)\n",
    "\n",
    "A_gpu = ROCMatrix(A_cpu)\n",
    "b_gpu = ROCVector(b_cpu)\n",
    "\n",
    "# Solve a dense Hermitian system on an AMD GPU\n",
    "x, stats = minres(A_gpu, b_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All solvers in Krylov.jl, can be used with [oneAPI.jl](https://github.com/JuliaGPU/oneAPI.jl) and allow computations on Intel GPUs.\n",
    "Problems stored in CPU format (`Matrix` and `Vector`) must first be converted to the related GPU format (`oneMatrix` and `oneVector`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Krylov, oneAPI\n",
    "\n",
    "T = Float32  # oneAPI.jl also works with ComplexF32\n",
    "m = 20\n",
    "n = 10\n",
    "\n",
    "# CPU Arrays\n",
    "A_cpu = rand(T, m, n)\n",
    "b_cpu = rand(T, m)\n",
    "\n",
    "# GPU Arrays\n",
    "A_gpu = oneMatrix(A_cpu)\n",
    "b_gpu = oneVector(b_cpu)\n",
    "\n",
    "# Solve a dense least-squares problem on an Intel GPU\n",
    "x, stats = lsqr(A_gpu, b_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All solvers in Krylov.jl, can be used with [Metal.jl](https://github.com/JuliaGPU/Metal.jl) and allow computations on Apple M1 GPUs.\n",
    "Problems stored in CPU format (`Matrix` and `Vector`) must first be converted to the related GPU format (`MtlMatrix` and `MtlVector`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Krylov, Metal\n",
    "\n",
    "T = Float32  # Metal.jl also works with ComplexF32\n",
    "n = 10\n",
    "m = 20\n",
    "\n",
    "# CPU Arrays\n",
    "A_cpu = rand(T, n, m)\n",
    "b_cpu = rand(T, n)\n",
    "\n",
    "# GPU Arrays\n",
    "A_gpu = MtlMatrix(A_cpu)\n",
    "b_gpu = MtlVector(b_cpu)\n",
    "\n",
    "# Solve a dense least-norm problem on an Apple M1 GPU\n",
    "x, stats = craig(A_gpu, b_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V) Support for linear operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input arguments of all Krylov.jl solvers that model $A$, $B$, $M$, $N$ and preconditioners can be any object that represents a linear operator.\n",
    "\n",
    "Krylov methods combined with linear operators allow to reduce computation time and memory requirements considerably by avoiding building and storing matrices.\n",
    "\n",
    "In nonlinear optimization, finding a critical point of a continuous function frequently involves linear systems where $A$ is a Hessian or a Jacobian.\n",
    "\n",
    "Materializing such operators as matrices is expensive in terms of operations and memory consumption and is unreasonable for high-dimensional problems.\n",
    "\n",
    "However, it is often possible to implement efficient Hessian-vector and Jacobian-vector products, for example with the help of automatic differentiation tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI) In-place methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All solvers in Krylov.jl have an in-place variant that allows to solve multiple linear systems with the same dimensions, precision and architecture.\n",
    "\n",
    "Optimization methods such as the Newton and Gauss-Newton methods can take advantage of this functionality by allocating workspace for the solve only once.\n",
    "\n",
    "The in-place variants only require a Julia structure that contains all the storage needed by a Krylov method as additional argument.\n",
    "\n",
    "In-place methods limit memory allocations and deallocations, which are particularly expensive on GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All solvers in Krylov.jl have an in-place variant implemented in a method whose name ends with `!`.\n",
    "A workspace (`KrylovSolver`) that contains the storage needed by a Krylov method can be used to solve multiple linear systems that have the same dimensions in the same floating-point precision.\n",
    "Each `KrylovSolver` has two constructors:\n",
    "\n",
    "```julia\n",
    "XyzSolver(A, b)\n",
    "XyzSolver(m, n, S)\n",
    "\n",
    "```\n",
    "\n",
    "`Xyz` is the name of the Krylov method with lowercase letters except its first one (`Cg`, `Minres`, `Lsmr`, `Bicgstab`, ...).\n",
    "Given an operator `A` and a right-hand side `b`, you can create a `KrylovSolver` based on the size of `A` and the type of `b` or explicitly give the dimensions `(m, n)` and the storage type `S`.\n",
    "\n",
    "For example, use `S = Vector{Float64}` if you want to solve linear systems in double precision on the CPU.\n",
    "\n",
    "The workspace is always the first argument of the in-place methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```julia\n",
    "minres_solver = MinresSolver(n, n, Vector{Float64})\n",
    "minres!(minres_solver, A, b)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VII) Performance optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operator-vector products and vector operations are the most expensive operations in Krylov.jl.\n",
    "\n",
    "We rely on BLAS routines as much as possible to perform those operations.\n",
    "\n",
    "By default, Julia ships with OpenBLAS and provides multithreaded routines.\n",
    "\n",
    "Since Julia 1.6, users can also switch dynamically to other BLAS backends, such as the Intel MKL or BLIS, thanks to the BLAS demuxing library `libblastrampoline`, if an optimized BLAS is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "BLAS.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import LinearAlgebra, OpenBLAS32_jll\n",
    "LinearAlgebra.BLAS.lbt_forward(OpenBLAS32_jll.libopenblas_path)\n",
    "BLAS.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import LinearAlgebra, MKL_jll\n",
    "LinearAlgebra.BLAS.lbt_forward(MKL_jll.libmkl_rt_path)\n",
    "BLAS.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import LinearAlgebra, blis_jll\n",
    "LinearAlgebra.BLAS.lbt_forward(blis_jll.blis_path)\n",
    "BLAS.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osx = false\n",
    "if osx\n",
    "  blas = \"/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/libBLAS.dylib\"\n",
    "  lapack = \"/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/libLAPACK.dylib\"\n",
    "  LinearAlgebra.BLAS.lbt_forward(blas, clear=true, verbose=true)\n",
    "  LinearAlgebra.BLAS.lbt_forward(lapack, clear=false, verbose=true)\n",
    "end\n",
    "BLAS.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIII) Storage requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A “Storage Requirements” section is available in the documentation to provide the theoretical number of bytes required by each method.\n",
    "\n",
    "Our implementations are storage-optimal in the sense that they are guaranteed to match the theoretical storage amount.\n",
    "\n",
    "The match is verified in the unit tests by way of functions that return the number of bytes allocated by our implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Krylov\n",
    "\n",
    "m = 5000\n",
    "n = 12000\n",
    "A = rand(Float64, m, n)\n",
    "b = rand(Float64, m)\n",
    "solver = LsmrSolver(A, b)\n",
    "show(stdout, solver, show_stats=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbytes = sizeof(solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FC = Float64                            # precision of the least-squares problem\n",
    "ncoefs_lsmr = 5*n + 2*m                 # number of coefficients\n",
    "nbytes_lsmr = sizeof(FC) * ncoefs_lsmr  # number of bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IX) Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first example is a simple implementation of the Gauss-Newton method without linesearch for nonlinear least squares.\n",
    "It illustrates several of the facilities of Krylov.jl: solver preallocation and reuse, genericity with respect to data types, and linear operators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "$$\\left.J(x_k) u = \\dfrac{d}{dt} F(x_k + tu) \\right|_{t=0}$$\n",
    "<br/><br/>\n",
    "$$\\left.J^T(x_k) w = \\dfrac{d}{dx} F(x)^T w \\right|_{x=x_k}$$\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra    # Linear algebra library of Julia\n",
    "using SparseArrays     # Sparse library of Julia\n",
    "using Krylov           # Krylov methods and processes\n",
    "using LinearOperators  # Linear operators\n",
    "using ForwardDiff      # Automatic differentiation\n",
    "using Quadmath         # Quadruple precision\n",
    "using MKL              # Intel BLAS\n",
    "\n",
    "\"The Gauss-Newton method for Nonlinear Least Squares\"\n",
    "function gauss_newton(F, JF, x₀::AbstractVector{T}; itmax = 200, tol = √eps(T)) where T\n",
    "    n = length(x₀)\n",
    "    x = copy(x₀)\n",
    "    Fx = F(x)\n",
    "    m = length(Fx)\n",
    "    iter = 0\n",
    "    S = typeof(x)                 # precision and architecture\n",
    "    solver = LsmrSolver(m, n, S)  # structure that contains the workspace of LSMR\n",
    "    solved = tired = false\n",
    "    while !(solved || tired)\n",
    "        Jx = JF(x)              # Compute J(xₖ)\n",
    "        lsmr!(solver, Jx, -Fx)  # Minimize ‖J(xₖ)Δx + F(xₖ)‖\n",
    "        x .+= solver.x          # Update xₖ₊₁ = xₖ + Δx\n",
    "        Fx_old = Fx             # F(xₖ)\n",
    "        Fx = F(x)               # F(xₖ₊₁)\n",
    "        iter += 1\n",
    "        solved = norm(Fx - Fx_old) / norm(Fx) ≤ tol\n",
    "        tired = iter ≥ itmax\n",
    "    end\n",
    "    return x\n",
    "end\n",
    "\n",
    "T = Float128  # IEEE quadruple precision\n",
    "x₀ = ones(T, 2)\n",
    "F(x) = [x[1]^4 - 3; exp(x[2]) - 2; log(x[1]) - x[2]^2]         # F(x)\n",
    "J(y, x, v) = ForwardDiff.derivative!(y, t -> F(x + t * v), 0)  # y ← JF(x)v\n",
    "Jᵀ(y, x, w) = ForwardDiff.gradient!(y, x -> dot(F(x), w), x)   # y ← JFᵀ(x)w\n",
    "symmetric = hermitian = false\n",
    "JF(x) = LinearOperator(T, 3, 2, symmetric, hermitian, (y, v) -> J(y, x, v),   # non-transpose\n",
    "                                                      (y, w) -> Jᵀ(y, x, w),  # transpose\n",
    "                                                      (y, w) -> Jᵀ(y, x, w))  # conjugate transpose\n",
    "gauss_newton(F, JF, x₀)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example based on a simplistic Newton method without linesearch for convex optimization:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\left.\\nabla^2 f(x_k) v = \\dfrac{d}{dt} \\nabla f(x_k + tv) \\right|_{t=0}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"The Newton method for convex optimization\"\n",
    "function newton(∇f, ∇²f, x₀::AbstractVector{T}; itmax = 200, tol = √eps(T)) where T\n",
    "    n = length(x₀)\n",
    "    x = copy(x₀)\n",
    "    gx = ∇f(x)\n",
    "    iter = 0\n",
    "    S = typeof(x)               # precision and architecture\n",
    "    solver = CgSolver(n, n, S)  # structure that contains the workspace of CG\n",
    "    solved = tired = false\n",
    "    while !(solved || tired)\n",
    "        Hx = ∇²f(x)           # Compute ∇²f(xₖ)\n",
    "        cg!(solver, Hx, -gx)  # Solve ∇²f(xₖ)Δx = -∇f(xₖ)\n",
    "        x .+= solver.x        # Update xₖ₊₁ = xₖ + Δx\n",
    "        gx = ∇f(x)            # ∇f(xₖ₊₁)\n",
    "        iter += 1\n",
    "        solved = norm(gx) ≤ tol\n",
    "        tired = iter ≥ itmax\n",
    "    end\n",
    "    return x\n",
    "end\n",
    "T = Float16  # IEEE half precision\n",
    "n = 4\n",
    "x₀ = -ones(T, n)\n",
    "f(x) = sum((x[i] - i)^2 for i = 1:n)                                # f(x)\n",
    "∇f(x) = ForwardDiff.gradient(f, x)                                  # ∇f(x)\n",
    "H(y, x, v) = ForwardDiff.derivative!(y, t -> ∇f(x + t * v), 0)      # y ← ∇²f(x)v\n",
    "symmetric = hermitian = true\n",
    "∇²f(x) = LinearOperator(T, n, n, symmetric, hermitian, (y, v) -> H(y, x, v))  # ∇²f(x)\n",
    "newton(∇f, ∇²f, x₀)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our second example concerns the solution of a complex Hermitian linear system from the [SuiteSparse Matrix Collection](https://sparse.tamu.edu/) with an incomplete Cholesky factorization preconditioner on GPU.\n",
    "\n",
    "The preconditioner $P$ is implemented as an in-place linear operator that performs the forward and backward sweeps with the Cholesky factor to model $P^{-1}$.\n",
    "\n",
    "Because the system matrix is Hermitian and positive definite, we use the conjugate gradient method.\n",
    "\n",
    "However, other methods for Hermitian systems could be used, including _Symmlq_, _Cr_ and _Minres_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra                # Linear algebra library of Julia\n",
    "using SparseArrays                 # Sparse library of Julia\n",
    "using Krylov                       # Krylov methods and processes\n",
    "using LinearOperators              # Linear operators\n",
    "using MatrixMarket                 # Reader of matrices stored in the Matrix Market format\n",
    "using SuiteSparseMatrixCollection  # Interface to the SuiteSparse Matrix Collection\n",
    "using CUDA                         # Interface to Nvidia GPUs\n",
    "using CUDA.CUSPARSE                # Nvidia CUSPARSE library\n",
    "\n",
    "ssmc = ssmc_db()\n",
    "matrices = ssmc_matrices(ssmc, \"Bai\", \"mhd1280b\")\n",
    "paths = fetch_ssmc(matrices, format=\"MM\")\n",
    "path_A = joinpath(paths[1], \"mhd1280b.mtx\")\n",
    "A_cpu = MatrixMarket.mmread(path_A)\n",
    "m, n = size(A_cpu)\n",
    "b_cpu = ones(ComplexF64, m)\n",
    "\n",
    "# Transfer the linear system from the CPU to the GPU\n",
    "A_gpu = CuSparseMatrixCSR(A_cpu)\n",
    "b_gpu = CuVector(b_cpu)\n",
    "\n",
    "# Incomplete Cholesky decomposition LLᴴ ≈ A with zero fill-in\n",
    "P = ic02(A_gpu, 'O')\n",
    "\n",
    "# Solve Py = x\n",
    "function ldiv_ic0!(y, P, x)\n",
    "  copyto!(y, x)\n",
    "  ldiv!(LowerTriangular(P), y)   # Forward substitution with L\n",
    "  ldiv!(LowerTriangular(P)', y)  # Backward substitution with Lᴴ\n",
    "  return y\n",
    "end\n",
    "\n",
    "# Linear operator that model the preconditioner P⁻¹\n",
    "T = ComplexF64\n",
    "symmetric = false\n",
    "hermitian = true\n",
    "P⁻¹ = LinearOperator(T, m, n, symmetric, hermitian, (y, x) -> ldiv_ic0!(y, P, x))\n",
    "\n",
    "# Solve a Hermitian positive definite system with an incomplete Cholesky factorization preconditioner\n",
    "x, stats = cg(A_gpu, b_gpu, M=P⁻¹)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
